NHL Stats â€“ End-to-End Data Pipeline (Scraping â†’ Cleaning â†’ Analysis â†’ Insights)

This project demonstrates a complete data workflow for NHL player statistics â€” from automated data collection to analytical insights.
It is designed as a practical showcase of real-world data handling, including web scraping, data processing, exploratory analysis, and the generation of business-oriented recommendations.

The entire pipeline is reproducible via Jupyter notebooks.

ğŸ“Œ Project Objectives
```text
Automatically download raw HTML data from selected NHL statistics pages.

Parse, clean, and transform the data into structured datasets.

Analyze statistical patterns and team performance indicators.

Deliver interpretable insights and recommendations based on the results.
```
ğŸ“‚ Project Structure
```text
NHL_stats/
|
|-- data/
|   |-- raw/          # original scraped HTML samples
|   |-- interim/      # intermediate JSON outputs
|   `-- processed/    # final cleaned CSV datasets
|
|-- drivers/          # chromedriver / webdriver (not included in repo)
|
|-- notebooks/        # Jupyter notebooks (download, cleaning, analysis, business insights)
|
|-- requirements.txt
`-- README.md
```
ğŸš€ How to Run the Project
1. Clone the repository.

2. Install dependencies
pip install -r requirements.txt

3. Install the appropriate browser driver

This project uses Selenium for automated data collection.
You can use any supported browser, as long as you install the correct driver:

Browser	Driver	Link
Chrome	ChromeDriver	https://chromedriver.chromium.org/downloads

Firefox	GeckoDriver	https://github.com/mozilla/geckodriver/releases

Edge	EdgeDriver	https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/

Download the driver matching your browser version.

Place the executable inside the drivers/ folder.

4. Run the notebooks in order

01_DataDownload.ipynb â€“ automated scraping

02_DataProcessing.ipynb â€“ parsing & cleaning

03_DataAnalysis.ipynb â€“ exploration & statistical analysis

04_BusinessRecommendations.ipynb â€“ insights & interpretation

ğŸ› ï¸ Technologies Used
```text
Python

pandas

numpy

matplotlib

BeautifulSoup4

Selenium

Requests

Jupyter Notebook

HTML + JSON + CSV data formats
```

ğŸ“ˆ What This Project Demonstrates

âœ” Practical experience with web scraping
âœ” End-to-end ETL pipeline design
âœ” Data cleaning and transformation
âœ” Exploratory data analysis
âœ” Communication of insights and findings
âœ” Clean project structure and reproducibility
