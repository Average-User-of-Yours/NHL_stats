{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "558XhVVXfGK8"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this notebook is to extract and save information about hockey teams into JSON format, based on data from files located in the `/data/raw` directory, which were generated in the previous stage. The information to be scraped and saved includes:  \n",
    "\n",
    "- Team Name (`Team Name`),  \n",
    "- Year (`Year`),  \n",
    "- Number of wins (`Wins`),  \n",
    "- Number of losses (`Losses`),  \n",
    "- Number of overtime losses (`OT Losses` - Overtime Losses),  \n",
    "- Win percentage (`Win %`),  \n",
    "- Number of goals scored (`Goals For (GF)`),  \n",
    "- Number of goals conceded (`Goals Against (GA)`),  \n",
    "- Goal differential (`+ / -`).  \n",
    "\n",
    "Each collected record will be organized into a dictionary with the structure shown below and then added to the results list:  \n",
    "\n",
    "```python  \n",
    "{  \n",
    "    'Team Name': 'Boston Bruins',  \n",
    "    'Year': '1990',  \n",
    "    'Wins': '44',  \n",
    "    'Losses': '24',  \n",
    "    'OT Losses': '',  \n",
    "    'Win %': '0.55',  \n",
    "    'Goals For (GF)': '299',  \n",
    "    'Goals Against (GA)': '264',  \n",
    "    '+ / -': '35'  \n",
    "}  \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The resulting data will be saved in a file named hockey_teams.json, which will be placed in the `data/interim/` folder. This file will serve as a data source for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u5hG5rOfGK_"
   },
   "source": [
    "# Notebook Configuration\n",
    "\n",
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lVWklch6fGLA"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E37pRB3JfGLA"
   },
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxAHWKh7fGLB"
   },
   "source": [
    "## List of HTML files\n",
    "\n",
    "Using the `glob` module, finding all `html` files in the `data/raw` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kd6AfGWsfGLB"
   },
   "outputs": [],
   "source": [
    "source_list = glob.glob(r\"..\\data\\raw\\*.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZigRm-unfGLB"
   },
   "source": [
    "## Scraping\n",
    "\n",
    "Extracting data from `html` files, making sure to maintain the expected structure of a single record:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZWNiTH61fGLB"
   },
   "outputs": [],
   "source": [
    "for_conversion = []\n",
    "\n",
    "keys = [\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"Ot Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Against (GA)\", \"+ / -\"]\n",
    "expected_lenght = 9\n",
    "\n",
    "for source in source_list:\n",
    "    with open(source, \"r\", encoding=\"utf-8\") as opened:\n",
    "        opened_source = opened.read()\n",
    "        \n",
    "        soup = BeautifulSoup(opened_source, \"html.parser\")\n",
    "        \n",
    "        for data in soup.find_all(class_ =\"team\"):\n",
    "            new_data = data.get_text(strip = 1, separator=\"/\")\n",
    "            values = new_data.split(\"/\")\n",
    "            if len(values) < expected_lenght:\n",
    "                values.insert(4, \"\")\n",
    "                \n",
    "            data_dict = dict(zip(keys, values))\n",
    "            for_conversion.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4Ls8zhgBfKv_"
   },
   "outputs": [],
   "source": [
    "json_for_export = json.dumps(for_conversion, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96tkK70QfGLB"
   },
   "source": [
    "# Summary\n",
    "\n",
    "After extracting the relevant information, the final step in preparation for analysis is to save the data.\n",
    "\n",
    "### Saving the file\n",
    "Here, we save the data to `data/interim/` and name the file `hockey_teams.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VY4qaMYpfGLC"
   },
   "outputs": [],
   "source": [
    "with open(r\"..\\data\\interim\\hockey_teams.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(json_for_export)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
